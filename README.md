# Vehicle-Insurance-Fraud-Detection

üîç Final Observations & Insights ‚Äî Vehicle Insurance Fraud Detection

 Team Members: Akanksha Jondhale, Viswanath Iruku, Inchara Jayaram Anuradha
 
 Dataset: fraud_oracle.csv
 
 Approach: Supervised Classification using Logistic Regression, Random Forest, Neural Networks with Autoencoders


üìå Problem Overview:

Vehicle insurance fraud, including staged accidents and exaggerated injury claims, is a growing concern impacting insurance companies and policyholders alike. Our goal was to build predictive models that can distinguish between genuine and fraudulent claims using historical data and help insurers take proactive action.

üîß Preprocessing & Feature Engineering:

‚Ä¢	Handled over 30 categorical and numerical features with significant class imbalance in the target variable FraudFound_P.

‚Ä¢	Applied label encoding, one-hot encoding, and scaling to prepare features for modeling.

‚Ä¢	Created new features like Claim Complexity to capture hidden patterns (e.g., RepNumber / PolicyNumber).

‚Ä¢	Removed multicollinear features using correlation matrix analysis (threshold > 0.9).

‚Ä¢	Balanced the dataset using random oversampling to improve fraud detection performance.


üîç Key Insights from EDA:

‚Ä¢	Fraud is more frequent in urban areas, with older vehicles, and frequent address changes.

‚Ä¢	Claims without police reports or witnesses are more likely to be fraudulent.

‚Ä¢	Fraudulent claims often involve younger policyholders and lower vehicle value brackets.

‚Ä¢	Heatmaps and clustering plots revealed temporal and regional fraud patterns useful for further operational strategies.


üìä Modeling & Evaluation Results:
We evaluated three key models with resampled data:

‚úÖ Random Forest

‚Ä¢	Accuracy: 96%

‚Ä¢	Precision (Fraud): 98

‚Ä¢	Recall (Fraud): 95%

‚Ä¢	F1 Score: 96%

Observation: This model provided the best overall performance with strong balance between Type I and Type II errors.

‚úÖ Logistic Regression

‚Ä¢	Accuracy: 96%

‚Ä¢	Precision (Fraud): 98%

‚Ä¢	Recall (Fraud): 94%

Observation: Similar to Random Forest, but slightly higher false negative rate. Still a robust and interpretable model.

‚ö†Ô∏è Neural Network (Autoencoder for Anomaly Detection)

‚Ä¢	Accuracy: 90%

‚Ä¢	Precision (Fraud): 7%

‚Ä¢	Recall (Fraud): 6%

Observation: Poor performance in detecting fraud due to subtle anomaly signatures and severe class imbalance. Better suited for unsupervised anomaly cases.

‚úÖ Conclusion:

Our project demonstrates that tree-based ensemble methods like Random Forests are highly effective for fraud detection when paired with thoughtful preprocessing and feature engineering. Balancing the dataset was critical for performance, and interpretability of models like logistic regression can support actionable decisions in real-world settings.
We recommend that insurers integrate such models into their claim pipeline to flag high-risk cases for further manual review, improving efficiency and reducing fraud-related losses.
